# Neural Networks from Scratch

This repository contains a detailed implementation of neural networks from scratch, designed to provide an intuitive understanding of their inner workings. The code avoids the use of high-level libraries such as TensorFlow or PyTorch, focusing instead on the fundamentals using Python and NumPy.

## Features

- **Activation Functions:** Implementation of commonly used activation functions like Sigmoid.
- **Step-by-Step Computation:** Demonstrates the core operations involved in neural networks.

## Requirements

To run the code in this project, you need:

- Python 3.7+
- NumPy

## Project Overview

The notebook includes:

1. **Introduction to Neural Networks:** A brief explanation of what neural networks are and their components.
2. **Activation Functions:** Implementation and visualization of the Sigmoid function.
3. **Forward Propagation:** Step-by-step computations.
4. **Backpropagation:** Manual derivation and implementation of the learning process.
